{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Awesome Open-source Machine Learning for Developers","text":"<p>List of resources, libraries and more for developers who would like to build with open-source machine learning off-the-shelf.</p> <p>Motivation: Developers are often building machine learning with closed-source models behind gated APIs. These models can change by time without developers knowing, companies are giving away their data during inference and have no control over the model nor data.</p> <p>There are a ton of open-source models out there that can be deployed by developers, but reducing barrier of entry to use these models and making developers aware of them are necessary, so I created this repository to do so.</p> <p>Using the resources here, you can learn to find the model you need and serve it on the platform of your choice using the tools given here.</p> <p>Hint: Take a look at foundation models section for one-model-fits-all type of models.</p> <p>Note: To contribute, send a pull request to this repository. Note that this repository is focused on open-source machine learning.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Resources</li> <li>Libraries, Platforms and Development Platform-specific Resources</li> <li>Platforms</li> <li>Development Platform<ul> <li>Framework</li> <li>Web</li> <li>Mobile</li> <li>Edge</li> <li>Cloud Deployment</li> <li>Serving</li> <li>Game Development</li> </ul> </li> <li>Modalities and Tasks</li> <li>Foundation Models</li> <li>LLMs<ul> <li>Tools</li> </ul> </li> <li>Multimodal Models<ul> <li>Models and Demos</li> <li>Understanding Image and Text</li> <li>Document AI</li> </ul> </li> <li>Generative AI<ul> <li>Models and Demos</li> </ul> </li> <li>Computer Vision<ul> <li>Models and Demos</li> </ul> </li> <li>Natural Language Processing</li> <li>Audio</li> <li>Advanced</li> </ul>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Tasks: A documentation project to let developers build their first machine learning based product using models off-the-shelf.</li> <li>Open-source AI Cookbook: Recipes and notebooks using open-source models and libraries.</li> </ul>"},{"location":"#libraries-platforms-and-development-platform-specific-resources","title":"Libraries, Platforms and Development Platform-specific Resources","text":""},{"location":"#platforms","title":"Platforms","text":"<ul> <li>Hugging Face Hub: Collaborative platform for machine learning. Discover hundreds of thousands of open-source models able to work off-the-shelf in /models.</li> <li>Kaggle Models: Discover and use thousands of machine learning models, including the most popular diffusion models and LLMs. </li> <li>Pytorch Hub: Discover and publish models to a pre-trained model repository designed for research exploration.</li> </ul>"},{"location":"#development-platform","title":"Development Platform","text":"<ul> <li>ONNX Runtime: Platform agnostic model runtime to use ML models.</li> </ul>"},{"location":"#framework","title":"Framework","text":"<ul> <li>TensorFlow: An end-to-end open source platform for machine learning.</li> <li>PyTorch: An open source machine learning framework that accelerates the path from research prototyping to production deployment.</li> </ul>"},{"location":"#web","title":"Web","text":"<ul> <li>Transformers.js: A library to run cutting edge models directly in-browser.</li> <li>huggingface.js: A library to play with models on Hugging Face Hub through javascript.</li> <li>TensorFlow.js: A library for machine learning in JavaScript.</li> <li>Mediapipe A framework that has prebuilt and customizable ML solutions, ready to deploy on Web</li> </ul>"},{"location":"#mobile","title":"Mobile","text":"<ul> <li>TensorFlow Lite: A library to deploy models on mobile and edge devices.</li> <li>Mediapipe: A framework that has prebuilt and customizable ML solutions, ready to deploy on Android, iOS.</li> <li>ExecuTorch: A library for enabling on-device ML in mobile/edge devices for PyTorch models.</li> <li>huggingface.dart: A Dart SDK to interact with the models on Hugging Face Hub.</li> <li>flutter-tflite: TensorFlow Lite Flutter plugin provides an easy, flexible, and fast Dart API to integrate TFLite models in flutter apps across mobile and desktop platforms.</li> <li>NCNN: A high-performance neural network inference framework optimized for the mobile platform.</li> </ul>"},{"location":"#edge","title":"Edge","text":"<ul> <li>TensorFlow Lite: A library to deploy models on mobile and edge devices.</li> <li>ExecuTorch: A library for enabling on-device ML in everywhere from AR/VR wearables to mobile/edge devices for PyTorch models.</li> </ul>"},{"location":"#cloud-deployment","title":"Cloud Deployment","text":""},{"location":"#serving","title":"Serving","text":"<ul> <li>Text Generation Inference: Toolkit to serve large language models.</li> <li>Text Embedding Inference: Toolkit to serve text embeddings.</li> <li>TorchServe: Flexible, easy to use and scalable inference server.</li> <li>Tensorflow Serving: Flexible, high-performance serving system for machine learning models, designed for production environments.</li> <li>Inference: A fast, easy-to-use, production-ready inference server for computer vision supporting deployment of many popular model architectures and fine-tuned models.</li> <li>Nvidia Triton Inference Server: Open source inference serving software that streamlines AI inferencing. Triton enables teams to deploy any AI model from multiple deep learning and machine learning frameworks, including TensorRT, TensorFlow, PyTorch, ONNX, OpenVINO, Python, RAPIDS FIL, and more.</li> <li>PyTrion: PyTriton is a Flask/FastAPI-like interface that simplifies Triton's deployment in Python environments. The library allows serving Machine Learning models directly from Python through NVIDIA's Triton Inference Server.</li> </ul>"},{"location":"#game-development","title":"Game Development","text":"<ul> <li> <p>MediaPipe Unity Plugin: Unity plugin to run MediaPipe. This approach may sacrifice performance when you need to call multiple APIs in a loop, but it gives you the flexibility to use MediaPipe instead.</p> </li> <li>Hugging Face API for Unity \ud83e\udd17: This Unity package provides an easy-to-use integration for the Hugging Face Inference API, allowing developers to access and use Hugging Face AI models within their Unity projects.</li> </ul>"},{"location":"#unity","title":"Unity","text":""},{"location":"#modalities-and-tasks","title":"Modalities and Tasks","text":"<p>This section contains powerful models that can generalize well and can be used out-of-the-box.</p>"},{"location":"#foundation-models","title":"Foundation Models","text":"<p>The following resources are on zero-shot models: These models take in an image or text and possible classes in those images or texts.</p> <ul> <li>Zero-shot Object Detection</li> <li>Zero-shot Image Classification Resources</li> <li>Zero-shot Text Classification Resources</li> </ul> <p>Note: The foundation model can be found under their associated task.</p>"},{"location":"#llms","title":"LLMs","text":""},{"location":"#tools","title":"Tools","text":"<ul> <li>Text Generation Inference: Toolkit to serve large language models.</li> <li>Text Embedding Inference: Toolkit to serve text embeddings.</li> <li>TGI Benchmark: Understanding throughput of inference servers, with TGI example.</li> <li>Open LLM Leaderboard: A leaderboard to find the open-source LLM for your use and budget.</li> <li>Ollama: Get up and running with Llama 2, Mistral, Gemma, and other large language models.</li> <li>Open Webui: Open WebUI is an extensible, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs.</li> </ul>"},{"location":"#multimodal-models","title":"Multimodal Models","text":"<ul> <li>Awesome Open-source Foundation and Multimodal Models: A curated list of models that have high zero-shot capabilities and the models that can take in two different modalities (e.g. a model that can take in image and text and output text).</li> </ul>"},{"location":"#models-and-demos","title":"Models and Demos","text":"<ul> <li>Kosmos-2: Demo for Kosmos-2 model by Microsoft, that can understand image and text, answer questions about images, caption images, detect objects on images and gives answer without hallucinating.</li> <li>Fuyu-8B: Demo for Fuyu-8b by Adept, that can understand image and text and answer questions about images and caption images.</li> </ul>"},{"location":"#understanding-image-and-text","title":"Understanding Image and Text","text":""},{"location":"#document-ai","title":"Document AI","text":"<ul> <li>Document AI Collection: A collection on demos and models for document AI.</li> </ul>"},{"location":"#generative-ai","title":"Generative AI","text":""},{"location":"#models-and-demos_1","title":"Models and Demos","text":"<ul> <li>Stable Cascade: An app based on state-of-the-art image generation model Stable Cascade. (as of March '24)</li> <li>Stable Diffusion XL Inpainting: An application that can do inpainting when given a text prompt and an image.</li> </ul>"},{"location":"#computer-vision","title":"Computer Vision","text":""},{"location":"#models-and-demos_2","title":"Models and Demos","text":"<ul> <li>OWL: A curation about OWL model released by Google, the most powerful zero-shot object detection model. (as of March '24)</li> <li>Segment Anything: A curation about Segment Anything model released by Meta, the most powerful zero-shot image segmentation model. (as of March '24)</li> <li>Depth Anything: A highly practical solution for robust monocular depth estimation by training on a combination of 1.5M labeled images and 62M+ unlabeled images.</li> </ul>"},{"location":"#natural-language-processing","title":"Natural Language Processing","text":""},{"location":"#audio","title":"Audio","text":"<ul> <li>Insanely Fast Whisper: A CLI to shrink and serve Whisper on-device.</li> <li>Open TTS Tracker: An awesome repository to keep a track of open-source text-to-speech models.</li> </ul>"},{"location":"#advanced","title":"Advanced","text":""},{"location":"#other","title":"Other","text":"<ul> <li>Raycast Automate commands on macOS apps with a local ollama LLM, with Raycast extensions.</li> </ul>"}]}